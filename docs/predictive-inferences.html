<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Predictive Inference | Application of a Principaled Bayesian Workflow to Multilevel Modeling</title>
  <meta name="description" content="5 Predictive Inference | Application of a Principaled Bayesian Workflow to Multilevel Modeling" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Predictive Inference | Application of a Principaled Bayesian Workflow to Multilevel Modeling" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="adkudson/thesis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Predictive Inference | Application of a Principaled Bayesian Workflow to Multilevel Modeling" />
  
  
  

<meta name="author" content="Alexander D. Knudson" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="model-checking.html"/>
<link rel="next" href="results.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#ch010-classical-methods"><i class="fa fa-check"></i><b>1.1</b> Everything can be Blamed on Fisher</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#ch010-new-methods"><i class="fa fa-check"></i><b>1.2</b> Proposal of New Methods</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#ch010-organization"><i class="fa fa-check"></i><b>1.3</b> Organization</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="motivating-data.html"><a href="motivating-data.html"><i class="fa fa-check"></i><b>2</b> What is a Model without Data</a><ul>
<li class="chapter" data-level="2.1" data-path="motivating-data.html"><a href="motivating-data.html#psycho-experiments"><i class="fa fa-check"></i><b>2.1</b> Psychometric Experiments</a></li>
<li class="chapter" data-level="2.2" data-path="motivating-data.html"><a href="motivating-data.html#toj-task"><i class="fa fa-check"></i><b>2.2</b> Temporal Order Judgment Data</a></li>
<li class="chapter" data-level="2.3" data-path="motivating-data.html"><a href="motivating-data.html#data-visualizations-and-quirks"><i class="fa fa-check"></i><b>2.3</b> Data Visualizations and Quirks</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="workflow.html"><a href="workflow.html"><i class="fa fa-check"></i><b>3</b> Principled Bayesian Workflow</a><ul>
<li class="chapter" data-level="3.1" data-path="workflow.html"><a href="workflow.html#iter1"><i class="fa fa-check"></i><b>3.1</b> Iteration 1 (journey of a thousand miles)</a></li>
<li class="chapter" data-level="3.2" data-path="workflow.html"><a href="workflow.html#iter2"><i class="fa fa-check"></i><b>3.2</b> Iteration 2 (electric boogaloo)</a></li>
<li class="chapter" data-level="3.3" data-path="workflow.html"><a href="workflow.html#iter3"><i class="fa fa-check"></i><b>3.3</b> Iteration 3 (the one for me)</a></li>
<li class="chapter" data-level="3.4" data-path="workflow.html"><a href="workflow.html#iter4"><i class="fa fa-check"></i><b>3.4</b> Iteration 4 (what’s one more)</a></li>
<li class="chapter" data-level="3.5" data-path="workflow.html"><a href="workflow.html#celebrate"><i class="fa fa-check"></i><b>3.5</b> Celebrate</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>4</b> Model Fitting/Checking</a><ul>
<li class="chapter" data-level="4.1" data-path="model-checking.html"><a href="model-checking.html#fitting-using-hmc"><i class="fa fa-check"></i><b>4.1</b> Fitting using HMC</a><ul>
<li class="chapter" data-level="4.1.1" data-path="model-checking.html"><a href="model-checking.html#diagnostic-tools"><i class="fa fa-check"></i><b>4.1.1</b> Diagnostic Tools</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="model-checking.html"><a href="model-checking.html#prior-predictive-checks"><i class="fa fa-check"></i><b>4.2</b> Prior Predictive Checks</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="predictive-inferences.html"><a href="predictive-inferences.html"><i class="fa fa-check"></i><b>5</b> Predictive Inference</a><ul>
<li class="chapter" data-level="5.1" data-path="predictive-inferences.html"><a href="predictive-inferences.html#model-comparison-via-predictive-performance"><i class="fa fa-check"></i><b>5.1</b> Model Comparison via Predictive Performance</a><ul>
<li class="chapter" data-level="5.1.1" data-path="predictive-inferences.html"><a href="predictive-inferences.html#loocv-and-importance-sampling"><i class="fa fa-check"></i><b>5.1.1</b> LOOCV and Importance Sampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>6</b> Psychometric Results</a><ul>
<li class="chapter" data-level="6.1" data-path="results.html"><a href="results.html#affect-of-adaptation-across-age-groups"><i class="fa fa-check"></i><b>6.1</b> Affect of Adaptation across Age Groups</a><ul>
<li class="chapter" data-level="6.1.1" data-path="results.html"><a href="results.html#on-perceptual-synchrony"><i class="fa fa-check"></i><b>6.1.1</b> On Perceptual Synchrony</a></li>
<li class="chapter" data-level="6.1.2" data-path="results.html"><a href="results.html#on-temporal-sensitivity"><i class="fa fa-check"></i><b>6.1.2</b> On Temporal Sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="results.html"><a href="results.html#lapse-rate-across-age-groups"><i class="fa fa-check"></i><b>6.2</b> Lapse Rate across Age Groups</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i><b>7</b> Discussion</a><ul>
<li class="chapter" data-level="7.1" data-path="discussion.html"><a href="discussion.html#model-selection-is-not-always-the-goal"><i class="fa fa-check"></i><b>7.1</b> Model selection is not always the goal</a></li>
<li class="chapter" data-level="7.2" data-path="discussion.html"><a href="discussion.html#data-cleaning-and-reproducibility"><i class="fa fa-check"></i><b>7.2</b> Data Cleaning and Reproducibility</a></li>
<li class="chapter" data-level="7.3" data-path="discussion.html"><a href="discussion.html#developing-a-model"><i class="fa fa-check"></i><b>7.3</b> Developing a model</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>8</b> Conclusion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="supplementary-code.html"><a href="supplementary-code.html"><i class="fa fa-check"></i><b>A</b> Supplementary Code</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Application of a Principaled Bayesian Workflow to Multilevel Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="predictive-inferences" class="section level1">
<h1><span class="header-section-number">5</span> Predictive Inference</h1>
<p><em>All models are wrong, but some are useful</em></p>
<p>The above quote is from George Box, and it is a popular quote that statisticians like to throw around<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>. All models are wrong because it is nearly impossible to account for the minutiae of every process that contributes to an observed phenomenon, and often trying to results in poorer performing models. Also is it ever truly possible to <em>prove</em> that a model is correct? At best our scientific method can falsify certain hypotheses, but it cannot ever tell us if a model is universally correct. That doesn’t matter. What does matter is if the model is useful and can make accurate predictions.</p>
<p>Why is predictive performance so important? Consider five points of data (figure <a href="predictive-inferences.html#fig:ch050-Moving-Moose">5.1</a>). I have simulated values from some polynomial equation of degree less than five, but with no more information other than that, how can the best polynomial model be selected?</p>
<div class="figure" style="text-align: center"><span id="fig:ch050-Moving-Moose"></span>
<img src="050-predictive-inference_files/figure-html/ch050-Moving-Moose-1.png" alt="Five points from a polynomial model." width="85%" />
<p class="caption">
Figure 5.1: Five points from a polynomial model.
</p>
</div>
<p>One thing to try is fit a handful of linear models, check the parameter’s p-values, the <span class="math inline">\(R^2\)</span> statistic, and perform other goodness of fit tests, but there is a problem. As you increase the degree of the polynomial fit, the <span class="math inline">\(R^2\)</span> statistic will always increase. In fact with five data points, a fourth degree polynomial will fit the data perfectly (figure <a href="predictive-inferences.html#fig:ch050-Olive-Screwdriver">5.2</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:ch050-Olive-Screwdriver"></span>
<img src="050-predictive-inference_files/figure-html/ch050-Olive-Screwdriver-1.png" alt="Data points with various polynomial regression lines." width="85%" />
<p class="caption">
Figure 5.2: Data points with various polynomial regression lines.
</p>
</div>
<p>If I were to add a <span class="math inline">\(6^{th}\)</span> point - a new observation - which of the models would you expect to do best? Can it be estimated which model will predict best before testing with new data? One guess is that the quadratic or cubic model will do well because because the linear model is potentially <em>underfit</em> to the data and the quartic is <em>overfit</em> to the data. Figure <a href="predictive-inferences.html#fig:ch050-Cold-Fish">5.3</a> shows the new data point from the polynomial model. Now the linear and cubic models are trending in the wrong direction. The quadratic and quartic models are both trending down, so may be the correct form for the model.</p>
<div class="figure" style="text-align: center"><span id="fig:ch050-Cold-Fish"></span>
<img src="050-predictive-inference_files/figure-html/ch050-Cold-Fish-1.png" alt="The fitted polynomial models with a new observation." width="85%" />
<p class="caption">
Figure 5.3: The fitted polynomial models with a new observation.
</p>
</div>
<p>Figure <a href="predictive-inferences.html#fig:ch050-Strawberry-Swallow">5.4</a> shows the 80% and 95% prediction intervals for a new observation given <span class="math inline">\(x = 5\)</span> as well as the true outcome as a dashed line at <span class="math inline">\(y = -3.434\)</span>. The linear model has the smallest prediction interval (PI), but completely misses the target. The remaining three models all include the observed value in their 95% PIs, but the quadratic has the smallest PI of the three. The actual data generating polynomial is</p>
<p><span class="math display">\[
y \sim \mathcal{N}(\mu, 1^2) \\
\mu = -0.5(x - 2)^2 + 2
\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:ch050-Strawberry-Swallow"></span>
<img src="050-predictive-inference_files/figure-html/ch050-Strawberry-Swallow-1.png" alt="95% Prediction intervals for the four polynomial models, as well as the true value (dashed line)." width="85%" />
<p class="caption">
Figure 5.4: 95% Prediction intervals for the four polynomial models, as well as the true value (dashed line).
</p>
</div>
<p>This is just a toy example, and real-world real-data models are often more complex, but they do present the same headaches when it comes to model/feature selection and goodness of fit checks. Clearly the quartic model has the best fit to the data, but it is too variable and doesn’t capture the regular features of the data, so it does poorly for the out-of-sample prediction. The linear model suffers as well by being less biased and too inflexible to capture the structure of the data. The quadratic and cubic are in the middle of the road, but the quadratic does well and makes fewer assumptions about the data. In other words, the quadratic model is just complex enough to predict well while making fewer assumptions. <em>Information criteria</em> is a way of weighing the prediction quality of a model against its complexity, and is arguably a better system for model selection/comparison than other goodness of fit statistics such as <span class="math inline">\(R^2\)</span> or p-values.</p>
<div id="model-comparison-via-predictive-performance" class="section level2">
<h2><span class="header-section-number">5.1</span> Model Comparison via Predictive Performance</h2>
<p>We don’t always have the observed data to compare predictions against (nor the data generating model). Some techniques to compensate for this limitation include cross validation, where the data is split into <em>training</em> data and <em>testing</em> data. The model is fit to the training data, and then predictions are made with the testing data and compared to the observed values. This can often give a good estimate for out-of-sample prediction error. Cross validation can be extended into k-fold cross validation. The idea is to <em>fold</em> the data into <span class="math inline">\(k\)</span> disjoint partitions, and predict partition <span class="math inline">\(i\)</span> using the rest of the data to train on. The prediction error of the <span class="math inline">\(k\)</span>-folds can then be averaged over to get an estimate for out-of-sample prediction error.</p>
<p>Taking <span class="math inline">\(k\)</span>-fold CV to the limit by letting <span class="math inline">\(k = \# observations\)</span> results in something called <em>leave one out cross validation</em> (LOOCV), where for each observation in the data, the model is fit to the remaining data and predicted for the left out observation. The downside of <span class="math inline">\(k\)</span>-fold cross validation is that it requires fitting the model <span class="math inline">\(k\)</span> times, which can be computationally expensive for complex Bayesian models. Thankfully there is a way to approximate LOOCV without having to refit the model many times.</p>
<div id="loocv-and-importance-sampling" class="section level3">
<h3><span class="header-section-number">5.1.1</span> LOOCV and Importance Sampling</h3>
<p>LOOCV and many other evaluation tools such as WAIC rest on the <em>log-pointwise-predictive-density</em> (lppd), which is a loose measure of deviance from some “true” probability distribution. Typically we don’t have the analytic form of the predictive posterior, so instead we use <span class="math inline">\(S\)</span> MCMC draws to approximate the lppd <span class="citation">(Vehtari, Gelman, and Gabry <a href="#ref-vehtari2017practical" role="doc-biblioref">2017</a>)</span>:</p>
<p><span class="math display" id="eq:lppd">\[
\begin{equation}
\mathrm{lppd}(y, \Theta) = \sum_i \log \frac{1}{S} \sum_s p(y_i | \Theta_s)
\tag{5.1}
\end{equation}
\]</span></p>
<p>To estimate LOOCV, the relative “importance” of each observation must be computed. Certain observations have more influence on the posterior distribution, and so have more impact on the posterior if they are removed. The intuition behind measuring importance is that more influential observations are relatively less likely than less important observations that are relatively expected. Then by omitting a sample, the relative importance weight can be measured by the lppd. This omitted calculation is known as the out-of-sample lppd. For each omitted <span class="math inline">\(y_i\)</span>,</p>
<p><span class="math display">\[
\mathrm{lppd}_{CV} = \sum_i \frac{1}{S} \sum_s \log p(y_{i} | \Theta_{-i,s})
\]</span></p>
<p>There is a package called <code>loo</code> that can compute the expected log-pointwise-posterior-density (ELPD) using PSIS-LOO, as well as the estimated number of effective parameters and LOO information criterion <span class="citation">(Vehtari, Gabry, et al. <a href="#ref-R-loo" role="doc-biblioref">2020</a>)</span>. For the part of the researcher, the log-likelihood of the observations must be computed in the model. For my models, I added this in the <em>generated quantities</em> block of my Stan program. It is standard practice to name the log-likelihood as <code>log_lik</code> in the model.</p>
<pre><code>generated quantities {
  vector[N] log_lik;

  for (i in 1:N) {
    real alpha = b + bGT[G[i], trt[i]];
    real beta = a + aGT[G[i], trt[i]];
    real lambda = lG[G[i]];
    real p = lambda + (1 - 2*lambda) * inv_logit(exp(beta) * (x[i] - alpha));
    log_lik[i] = binomial_lpmf(k[i] | n[i], p);
  }
}</code></pre>
<p>Models can be compared simply using <code>loo::loo_compare</code>. It estimated the ELPD and its standard error, then calculates the relative differences between all the models. The model with the highest ELPD is predicted to have the best out-of-sample predictions. The comparison of the first three iterations of the model from <a href="workflow.html#workflow">chapter 3</a> for the audiovisual data are shown below.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="predictive-inferences.html#cb26-1"></a>comp_av &lt;-<span class="st"> </span><span class="kw">loo_compare</span>(l031_av, l032_av, l032nc_av, l033_av)</span>
<span id="cb26-2"><a href="predictive-inferences.html#cb26-2"></a><span class="kw">print</span>(comp_av, <span class="dt">simplify =</span> <span class="ot">FALSE</span>)</span>
<span id="cb26-3"><a href="predictive-inferences.html#cb26-3"></a><span class="co">#&gt;        elpd_diff se_diff elpd_loo se_elpd_loo p_loo   se_p_loo looic   se_looic</span></span>
<span id="cb26-4"><a href="predictive-inferences.html#cb26-4"></a><span class="co">#&gt; model4     0.0       0.0 -1615.7     42.8        16.2     0.9   3231.4    85.6 </span></span>
<span id="cb26-5"><a href="predictive-inferences.html#cb26-5"></a><span class="co">#&gt; model2    -1.0       3.8 -1616.7     42.6        11.3     0.6   3233.3    85.2 </span></span>
<span id="cb26-6"><a href="predictive-inferences.html#cb26-6"></a><span class="co">#&gt; model3    -1.3       3.8 -1617.0     42.7        11.8     0.6   3234.0    85.3 </span></span>
<span id="cb26-7"><a href="predictive-inferences.html#cb26-7"></a><span class="co">#&gt; model1   -32.8      10.4 -1648.5     43.0         3.0     0.2   3296.9    86.1</span></span></code></pre></div>
<p>The centered and non-centered parameterizations (models 2 and 3 respectively) have essentially the same ELPD. This is expected since they are essentially the same model. The reparameterization only helps with model fitting efficiency, though that can mean more reliable posteriors. The model with age-block interactions (model 4) has the highest ELPD, but is not decisively the best as determined by the standard error of the ELPD. The only thing that can be determined is that including age and block improves performance significantly over the base model (model 1).</p>
<p>But how about for the visual data? The fourth iteration of the model introduced a lapse rate. Did the change significantly improve the ELPD?</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="predictive-inferences.html#cb27-1"></a>comp_vis &lt;-<span class="st"> </span><span class="kw">loo_compare</span>(l033_vis, l034_vis)</span>
<span id="cb27-2"><a href="predictive-inferences.html#cb27-2"></a><span class="kw">print</span>(comp_vis, <span class="dt">simplify =</span> <span class="ot">FALSE</span>)</span>
<span id="cb27-3"><a href="predictive-inferences.html#cb27-3"></a><span class="co">#&gt;        elpd_diff se_diff elpd_loo se_elpd_loo p_loo   se_p_loo looic   se_looic</span></span>
<span id="cb27-4"><a href="predictive-inferences.html#cb27-4"></a><span class="co">#&gt; model2     0.0       0.0 -1001.1     44.0        19.2     1.9   2002.2    88.0 </span></span>
<span id="cb27-5"><a href="predictive-inferences.html#cb27-5"></a><span class="co">#&gt; model1  -259.4      31.9 -1260.5     56.1        23.1     2.3   2520.9   112.2</span></span></code></pre></div>
<p>Absolutely! Something else interesting also happened with the introduction of the lapse rate - the effective number of parameters decreased (<code>p_loo</code>).</p>
<p>Earlier I argued that model selection is out, model comparison is in. At the end of <a href="workflow.html#workflow">chapter 3</a> I finished with a model that has age-block interactions and a lapse rate for each age group. There was one more model that I could have specified - one that estimates at the subject level. There is no domain-specific reason to include the subject level information, especially since the goal is to make inferences at the age group level, but there may still be statistical reason to add in the subjects. For one, adding in the subject as another level in a multilevel model can induce regularization among the subjects, which can overall make for better predictions on new data.</p>
<p>I’ve gone ahead and fit the model with subject-level information, and the comparison between this new model and the one from iteration 4 is shown below.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="predictive-inferences.html#cb28-1"></a>comp_vis2 &lt;-<span class="st"> </span><span class="kw">loo_compare</span>(l034_vis, l034s_vis)</span>
<span id="cb28-2"><a href="predictive-inferences.html#cb28-2"></a><span class="kw">print</span>(comp_vis2, <span class="dt">simplify =</span> <span class="ot">FALSE</span>)</span>
<span id="cb28-3"><a href="predictive-inferences.html#cb28-3"></a><span class="co">#&gt;        elpd_diff se_diff elpd_loo se_elpd_loo p_loo   se_p_loo looic   se_looic</span></span>
<span id="cb28-4"><a href="predictive-inferences.html#cb28-4"></a><span class="co">#&gt; model2     0.0       0.0  -925.1     38.1        75.6     5.4   1850.3    76.2 </span></span>
<span id="cb28-5"><a href="predictive-inferences.html#cb28-5"></a><span class="co">#&gt; model1   -76.0      19.1 -1001.1     44.0        19.2     1.9   2002.2    88.0</span></span></code></pre></div>
<p>Including the subject-level information significantly improves the ELPD, and even though there are over 100 parameters in the model (slope and intercept for each of the 45 subjects), the effective number of parameters is much less. Since this new model is capable of making inferences at both the age group level and the subject level, I use it for the result section (<a href="results.html#results">chapter 6</a>).</p>
<p>One concern comes up when it comes to LOOCV and multilevel models. What does it mean to leave <em>one</em> out? Should one subject be left out? One age group? Just one observation? With more levels in a model, more careful considerations must be taken when it comes to estimating prediction performance.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-loo">
<p>Vehtari, Aki, Jonah Gabry, Mans Magnusson, Yuling Yao, Paul-Christian Bürkner, Topi Paananen, and Andrew Gelman. 2020. <em>Loo: Efficient Leave-One-Out Cross-Validation and Waic for Bayesian Models</em>. <a href="https://CRAN.R-project.org/package=loo">https://CRAN.R-project.org/package=loo</a>.</p>
</div>
<div id="ref-vehtari2017practical">
<p>Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and Waic.” <em>Statistics and Computing</em> 27 (5): 1413–32.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="9">
<li id="fn9"><p>I am one of them<a href="predictive-inferences.html#fnref9" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="model-checking.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="results.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/adknudson/thesis/blob/master/050-predictive-inference.Rmd",
"text": null
},
"download": ["adknudson-thesis.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toc_depth": 3,
"toolbar": {
"position": "fixed"
},
"search": true,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
